{
  "version": "2.0",
  "service": "<p>Operations and objects for transcribing streaming speech to text.</p>",
  "operations": {
    "StartMedicalStreamTranscription": "<p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe Medical and the transcription results are streamed to your application.</p>",
    "StartStreamTranscription": "<p>Starts a bidirectional HTTP/2 stream where audio is streamed to Amazon Transcribe and the transcription results are streamed to your application.</p> <p>The following are encoded as HTTP/2 headers:</p> <ul> <li> <p>x-amzn-transcribe-language-code</p> </li> <li> <p>x-amzn-transcribe-media-encoding</p> </li> <li> <p>x-amzn-transcribe-sample-rate</p> </li> <li> <p>x-amzn-transcribe-session-id</p> </li> </ul> <p>See the <a href=\"https://docs.aws.amazon.com/sdk-for-go/api/service/transcribestreamingservice/#TranscribeStreamingService.StartStreamTranscription\"> SDK for Go API Reference</a> for more detail.</p>"
  },
  "shapes": {
    "Alternative": {
      "base": "<p>A list of possible transcriptions for the audio.</p>",
      "refs": {
        "AlternativeList$member": null
      }
    },
    "AlternativeList": {
      "base": null,
      "refs": {
        "Result$Alternatives": "<p>A list of possible transcriptions for the audio. Each alternative typically contains one <code>item</code> that contains the result of the transcription.</p>"
      }
    },
    "AudioChunk": {
      "base": null,
      "refs": {
        "AudioEvent$AudioChunk": "<p>An audio blob that contains the next part of the audio that you want to transcribe. The maximum audio chunk size is 32 KB.</p>"
      }
    },
    "AudioEvent": {
      "base": "<p>Provides a wrapper for the audio chunks that you are sending.</p> <p>For information on audio encoding in Amazon Transcribe, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/input.html\">Speech input</a>. For information on audio encoding formats in Amazon Transcribe Medical, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html\">Speech input</a>.</p>",
      "refs": {
        "AudioStream$AudioEvent": "<p>A blob of audio from your application. You audio stream consists of one or more audio events.</p> <p>For information on audio encoding formats in Amazon Transcribe, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/input.html\">Speech input</a>. For information on audio encoding formats in Amazon Transcribe Medical, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/input-med.html\">Speech input</a>.</p> <p>For more information on stream encoding in Amazon Transcribe, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html\">Event stream encoding</a>. For information on stream encoding in Amazon Transcribe Medical, see <a href=\"https://docs.aws.amazon.com/transcribe/latest/dg/event-stream-med.html\">Event stream encoding</a>.</p>"
      }
    },
    "AudioStream": {
      "base": "<p>Represents the audio stream from your application to Amazon Transcribe.</p>",
      "refs": {
        "StartMedicalStreamTranscriptionRequest$AudioStream": null,
        "StartStreamTranscriptionRequest$AudioStream": "<p>PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP/2 data frame.</p>"
      }
    },
    "BadRequestException": {
      "base": "<p>One or more arguments to the <code>StartStreamTranscription</code> or <code>StartMedicalStreamTranscription</code> operation was invalid. For example, <code>MediaEncoding</code> was not set to a valid encoding, or <code>LanguageCode</code> was not set to a valid code. Check the parameters and try your request again.</p>",
      "refs": {
        "MedicalTranscriptResultStream$BadRequestException": null,
        "TranscriptResultStream$BadRequestException": "<p>A client error occurred when the stream was created. Check the parameters of the request and try your request again.</p>"
      }
    },
    "Boolean": {
      "base": null,
      "refs": {
        "Item$VocabularyFilterMatch": "<p>Indicates whether a word in the item matches a word in the vocabulary filter you've chosen for your media stream. If <code>true</code> then a word in the item matches your vocabulary filter.</p>",
        "MedicalResult$IsPartial": "<p>Amazon Transcribe Medical divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments.</p> <p>The <code>IsPartial</code> field is <code>true</code> to indicate that Amazon Transcribe Medical has additional transcription data to send. The <code>IsPartial</code> field is <code>false</code> to indicate that this is the last transcription result for the segment.</p>",
        "Result$IsPartial": "<p>Amazon Transcribe divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments. </p> <p>The <code>IsPartial</code> field is <code>true</code> to indicate that Amazon Transcribe has additional transcription data to send, <code>false</code> to indicate that this is the last transcription result for the segment.</p>",
        "StartMedicalStreamTranscriptionRequest$ShowSpeakerLabel": "<p>When <code>true</code>, enables speaker identification in your real-time stream.</p>",
        "StartMedicalStreamTranscriptionRequest$EnableChannelIdentification": "<p>When <code>true</code>, instructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription.</p> <p>Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions.</p> <p>You can't set both <code>ShowSpeakerLabel</code> and <code>EnableChannelIdentification</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>",
        "StartMedicalStreamTranscriptionResponse$ShowSpeakerLabel": "<p>Shows whether speaker identification was enabled in the stream.</p>",
        "StartMedicalStreamTranscriptionResponse$EnableChannelIdentification": "<p>Shows whether channel identification has been enabled in the stream.</p>",
        "StartStreamTranscriptionRequest$ShowSpeakerLabel": "<p>When <code>true</code>, enables speaker identification in your media stream.</p>",
        "StartStreamTranscriptionRequest$EnableChannelIdentification": "<p>When <code>true</code>, instructs Amazon Transcribe to process each audio channel separately, then merges the transcription output of each channel into a single transcription.</p> <p>Amazon Transcribe also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions.</p> <p>You can't set both <code>ShowSpeakerLabel</code> and <code>EnableChannelIdentification</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>",
        "StartStreamTranscriptionRequest$EnablePartialResultsStabilization": "<p>When <code>true</code>, instructs Amazon Transcribe to present transcription results that have the partial results stabilized. Normally, any word or phrase from one partial result can change in a subsequent partial result. With partial results stabilization enabled, only the last few words of one partial result can change in another partial result.</p>",
        "StartStreamTranscriptionRequest$IdentifyLanguage": "<p>Optional. Set this value to <code>true</code> to enable language identification for your media stream.</p>",
        "StartStreamTranscriptionResponse$ShowSpeakerLabel": "<p>Shows whether speaker identification was enabled in the stream.</p>",
        "StartStreamTranscriptionResponse$EnableChannelIdentification": "<p>Shows whether channel identification has been enabled in the stream.</p>",
        "StartStreamTranscriptionResponse$EnablePartialResultsStabilization": "<p>Shows whether partial results stabilization has been enabled in the stream.</p>",
        "StartStreamTranscriptionResponse$IdentifyLanguage": "<p>The language code of the language identified in your media stream.</p>"
      }
    },
    "Confidence": {
      "base": null,
      "refs": {
        "Entity$Confidence": "<p>A value between zero and one that Amazon Transcribe assigns to PII identified in the source audio. Larger values indicate a higher confidence in PII identification.</p>",
        "Item$Confidence": "<p>A value between zero and one for an item that is a confidence score that Amazon Transcribe assigns to each word or phrase that it transcribes.</p>",
        "MedicalEntity$Confidence": "<p>A value between zero and one that Amazon Transcribe Medical assigned to the personal health information that it identified in the source audio. Larger values indicate that Amazon Transcribe Medical has higher confidence in the personal health information that it identified.</p>",
        "MedicalItem$Confidence": "<p>A value between 0 and 1 for an item that is a confidence score that Amazon Transcribe Medical assigns to each word that it transcribes.</p>"
      }
    },
    "ConflictException": {
      "base": "<p>A new stream started with the same session ID. The current stream has been terminated.</p>",
      "refs": {
        "MedicalTranscriptResultStream$ConflictException": null,
        "TranscriptResultStream$ConflictException": "<p>A new stream started with the same session ID. The current stream has been terminated.</p>"
      }
    },
    "ContentIdentificationType": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$ContentIdentificationType": "<p>Set this field to PII to identify personally identifiable information (PII) in the transcription output. Content identification is performed only upon complete transcription of the audio segments.</p> <p>You can’t set both <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>",
        "StartStreamTranscriptionResponse$ContentIdentificationType": "<p>Shows whether content identification was enabled in this stream.</p>"
      }
    },
    "ContentRedactionType": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$ContentRedactionType": "<p>Set this field to PII to redact personally identifiable information (PII) in the transcription output. Content redaction is performed only upon complete transcription of the audio segments.</p> <p>You can’t set both <code>ContentRedactionType</code> and <code>ContentIdentificationType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>",
        "StartStreamTranscriptionResponse$ContentRedactionType": "<p>Shows whether content redaction was enabled in this stream.</p>"
      }
    },
    "Double": {
      "base": null,
      "refs": {
        "Entity$StartTime": "<p>The start time of speech that was identified as PII.</p>",
        "Entity$EndTime": "<p>The end time of speech that was identified as PII.</p>",
        "Item$StartTime": "<p>The offset from the beginning of the audio stream to the beginning of the audio that resulted in the item.</p>",
        "Item$EndTime": "<p>The offset from the beginning of the audio stream to the end of the audio that resulted in the item.</p>",
        "LanguageWithScore$Score": "<p>The confidence score for the associated language code. Confidence scores are values between zero and one; larger values indicate a higher confidence in the identified language. </p>",
        "MedicalEntity$StartTime": "<p>The start time of the speech that was identified as a medical entity.</p>",
        "MedicalEntity$EndTime": "<p>The end time of the speech that was identified as a medical entity.</p>",
        "MedicalItem$StartTime": "<p>The number of seconds into an audio stream that indicates the creation time of an item.</p>",
        "MedicalItem$EndTime": "<p>The number of seconds into an audio stream that indicates the creation time of an item.</p>",
        "MedicalResult$StartTime": "<p>The time, in seconds, from the beginning of the audio stream to the beginning of the result.</p>",
        "MedicalResult$EndTime": "<p>The time, in seconds, from the beginning of the audio stream to the end of the result.</p>",
        "Result$StartTime": "<p>The offset in seconds from the beginning of the audio stream to the beginning of the result.</p>",
        "Result$EndTime": "<p>The offset in seconds from the beginning of the audio stream to the end of the result.</p>"
      }
    },
    "Entity": {
      "base": "<p>The entity identified as personally identifiable information (PII).</p>",
      "refs": {
        "EntityList$member": null
      }
    },
    "EntityList": {
      "base": null,
      "refs": {
        "Alternative$Entities": "<p>Contains the entities identified as personally identifiable information (PII) in the transcription output.</p>"
      }
    },
    "InternalFailureException": {
      "base": "<p>A problem occurred while processing the audio. Amazon Transcribe or Amazon Transcribe Medical terminated processing. Try your request again.</p>",
      "refs": {
        "MedicalTranscriptResultStream$InternalFailureException": null,
        "TranscriptResultStream$InternalFailureException": "<p>A problem occurred while processing the audio. Amazon Transcribe terminated processing.</p>"
      }
    },
    "Item": {
      "base": "<p>A word, phrase, or punctuation mark that is transcribed from the input audio.</p>",
      "refs": {
        "ItemList$member": null
      }
    },
    "ItemList": {
      "base": null,
      "refs": {
        "Alternative$Items": "<p>One or more alternative interpretations of the input audio. </p>"
      }
    },
    "ItemType": {
      "base": null,
      "refs": {
        "Item$Type": "<p>The type of the item. <code>PRONUNCIATION</code> indicates that the item is a word that was recognized in the input audio. <code>PUNCTUATION</code> indicates that the item was interpreted as a pause in the input audio.</p>",
        "MedicalItem$Type": "<p>The type of the item. <code>PRONUNCIATION</code> indicates that the item is a word that was recognized in the input audio. <code>PUNCTUATION</code> indicates that the item was interpreted as a pause in the input audio, such as a period to indicate the end of a sentence.</p>"
      }
    },
    "LanguageCode": {
      "base": null,
      "refs": {
        "LanguageWithScore$LanguageCode": "<p>The language code of the language identified by Amazon Transcribe.</p>",
        "Result$LanguageCode": "<p>The language code of the identified language in your media stream.</p>",
        "StartMedicalStreamTranscriptionRequest$LanguageCode": "<p> Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US English (en-US). </p>",
        "StartMedicalStreamTranscriptionResponse$LanguageCode": "<p>The language code for the response transcript. For Amazon Transcribe Medical, this is US English (en-US).</p>",
        "StartStreamTranscriptionRequest$LanguageCode": "<p>The language code of the input audio stream.</p>",
        "StartStreamTranscriptionRequest$PreferredLanguage": "<p>Optional. From the subset of languages codes you provided for <code>LanguageOptions</code>, you can select one preferred language for your transcription.</p> <p>You can only use this parameter if you've set <code>IdentifyLanguage</code> to <code>true</code>in your request.</p>",
        "StartStreamTranscriptionResponse$LanguageCode": "<p>The language code of the input audio stream.</p>",
        "StartStreamTranscriptionResponse$PreferredLanguage": "<p>The preferred language you specified in your request.</p>"
      }
    },
    "LanguageIdentification": {
      "base": null,
      "refs": {
        "Result$LanguageIdentification": "<p>The language code of the dominant language identified in your media.</p>"
      }
    },
    "LanguageOptions": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$LanguageOptions": "<p>An object containing a list of languages that might be present in your audio.</p> <p>You must provide two or more language codes to help Amazon Transcribe identify the correct language of your media stream with the highest possible accuracy. You can only select one variant per language; for example, you can't include both <code>en-US</code> and <code>en-UK</code> in the same request.</p> <p>You can only use this parameter if you've set <code>IdentifyLanguage</code> to <code>true</code>in your request.</p>",
        "StartStreamTranscriptionResponse$LanguageOptions": "<p>The language codes used in the identification of your media stream's predominant language.</p>"
      }
    },
    "LanguageWithScore": {
      "base": "<p>The language codes of the identified languages and their associated confidence scores. The confidence score is a value between zero and one; a larger value indicates a higher confidence in the identified language.</p>",
      "refs": {
        "LanguageIdentification$member": null
      }
    },
    "LimitExceededException": {
      "base": "<p>You have exceeded the maximum number of concurrent transcription streams, are starting transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream has finished processing, or break your audio stream into smaller chunks and try your request again.</p>",
      "refs": {
        "MedicalTranscriptResultStream$LimitExceededException": null,
        "TranscriptResultStream$LimitExceededException": "<p>Your client has exceeded one of the Amazon Transcribe limits, typically the limit on audio length. Break your audio stream into smaller chunks and try your request again.</p>"
      }
    },
    "MediaEncoding": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$MediaEncoding": "<p>The encoding used for the input audio.</p>",
        "StartMedicalStreamTranscriptionResponse$MediaEncoding": "<p>The encoding used for the input audio stream.</p>",
        "StartStreamTranscriptionRequest$MediaEncoding": "<p>The encoding used for the input audio.</p>",
        "StartStreamTranscriptionResponse$MediaEncoding": "<p>The encoding used for the input audio stream.</p>"
      }
    },
    "MediaSampleRateHertz": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$MediaSampleRateHertz": "<p>The sample rate of the input audio in Hertz.</p>",
        "StartMedicalStreamTranscriptionResponse$MediaSampleRateHertz": "<p>The sample rate of the input audio in Hertz.</p>",
        "StartStreamTranscriptionRequest$MediaSampleRateHertz": "<p>The sample rate, in Hertz (Hz), of the input audio. We suggest that you use 8,000 Hz for low quality audio and 16,000 Hz or higher for high quality audio.</p>",
        "StartStreamTranscriptionResponse$MediaSampleRateHertz": "<p>The sample rate, in Hertz (Hz), for the input audio stream. Use 8,000 Hz for low quality audio and 16,000 Hz or higher for high quality audio.</p>"
      }
    },
    "MedicalAlternative": {
      "base": "<p>A list of possible transcriptions for the audio.</p>",
      "refs": {
        "MedicalAlternativeList$member": null
      }
    },
    "MedicalAlternativeList": {
      "base": null,
      "refs": {
        "MedicalResult$Alternatives": "<p>A list of possible transcriptions of the audio. Each alternative typically contains one <code>Item</code> that contains the result of the transcription.</p>"
      }
    },
    "MedicalContentIdentificationType": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$ContentIdentificationType": "<p>Set this field to <code>PHI</code> to identify personal health information in the transcription output.</p>",
        "StartMedicalStreamTranscriptionResponse$ContentIdentificationType": "<p>If the value is <code>PHI</code>, indicates that you've configured your stream to identify personal health information.</p>"
      }
    },
    "MedicalEntity": {
      "base": "<p>The medical entity identified as personal health information.</p>",
      "refs": {
        "MedicalEntityList$member": null
      }
    },
    "MedicalEntityList": {
      "base": null,
      "refs": {
        "MedicalAlternative$Entities": "<p>Contains the medical entities identified as personal health information in the transcription output.</p>"
      }
    },
    "MedicalItem": {
      "base": "<p>A word, phrase, or punctuation mark that is transcribed from the input audio.</p>",
      "refs": {
        "MedicalItemList$member": null
      }
    },
    "MedicalItemList": {
      "base": null,
      "refs": {
        "MedicalAlternative$Items": "<p>A list of objects that contains words and punctuation marks that represents one or more interpretations of the input audio.</p>"
      }
    },
    "MedicalResult": {
      "base": "<p>The results of transcribing a portion of the input audio stream.</p>",
      "refs": {
        "MedicalResultList$member": null
      }
    },
    "MedicalResultList": {
      "base": null,
      "refs": {
        "MedicalTranscript$Results": "<p> <a>MedicalResult</a> objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.</p>"
      }
    },
    "MedicalTranscript": {
      "base": "<p>The medical transcript in a <a>MedicalTranscriptEvent</a>.</p>",
      "refs": {
        "MedicalTranscriptEvent$Transcript": "<p>The transcription of the audio stream. The transcription is composed of all of the items in the results list.</p>"
      }
    },
    "MedicalTranscriptEvent": {
      "base": "<p>Represents a set of transcription results from the server to the client. It contains one or more segments of the transcription.</p>",
      "refs": {
        "MedicalTranscriptResultStream$TranscriptEvent": "<p>A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe Medical to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream.</p>"
      }
    },
    "MedicalTranscriptResultStream": {
      "base": "<p>Represents the transcription result stream from Amazon Transcribe Medical to your application.</p>",
      "refs": {
        "StartMedicalStreamTranscriptionResponse$TranscriptResultStream": "<p>Represents the stream of transcription events from Amazon Transcribe Medical to your application. </p>"
      }
    },
    "ModelName": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$LanguageModelName": "<p>The name of the language model you want to use.</p>",
        "StartStreamTranscriptionResponse$LanguageModelName": "<p>The name of the language model used in your media stream.</p>"
      }
    },
    "NumberOfChannels": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$NumberOfChannels": "<p>The number of channels that are in your audio stream.</p>",
        "StartMedicalStreamTranscriptionResponse$NumberOfChannels": "<p>The number of channels identified in the stream.</p>",
        "StartStreamTranscriptionRequest$NumberOfChannels": "<p>The number of channels that are in your audio stream.</p>",
        "StartStreamTranscriptionResponse$NumberOfChannels": "<p>The number of channels identified in the stream.</p>"
      }
    },
    "PartialResultsStability": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$PartialResultsStability": "<p>You can use this field to set the stability level of the transcription results. A higher stability level means that the transcription results are less likely to change. Higher stability levels can come with lower overall transcription accuracy.</p>",
        "StartStreamTranscriptionResponse$PartialResultsStability": "<p>If partial results stabilization has been enabled in the stream, shows the stability level.</p>"
      }
    },
    "PiiEntityTypes": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$PiiEntityTypes": "<p>List the PII entity types you want to identify or redact. In order to specify entity types, you must have either <code>ContentIdentificationType</code> or <code>ContentRedactionType</code> enabled.</p> <p> <code>PIIEntityTypes</code> must be comma-separated; the available values are: <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>PIN</code>, <code>EMAIL</code>, <code>ADDRESS</code>, <code>NAME</code>, <code>PHONE</code>, <code>SSN</code>, and <code>ALL</code>.</p> <p> <code>PiiEntityTypes</code> is an optional parameter with a default value of <code>ALL</code>.</p>",
        "StartStreamTranscriptionResponse$PiiEntityTypes": "<p>Lists the PII entity types you specified in your request.</p>"
      }
    },
    "RequestId": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionResponse$RequestId": "<p>An identifier for the streaming transcription.</p>",
        "StartStreamTranscriptionResponse$RequestId": "<p>An identifier for the streaming transcription.</p>"
      }
    },
    "Result": {
      "base": "<p>The result of transcribing a portion of the input audio stream. </p>",
      "refs": {
        "ResultList$member": null
      }
    },
    "ResultList": {
      "base": null,
      "refs": {
        "Transcript$Results": "<p> <a>Result</a> objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.</p>"
      }
    },
    "ServiceUnavailableException": {
      "base": "<p>Service is currently unavailable. Try your request later.</p>",
      "refs": {
        "MedicalTranscriptResultStream$ServiceUnavailableException": null,
        "TranscriptResultStream$ServiceUnavailableException": "<p>Service is currently unavailable. Try your request later.</p>"
      }
    },
    "SessionId": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$SessionId": "<p> Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response. </p>",
        "StartMedicalStreamTranscriptionResponse$SessionId": "<p>Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.</p>",
        "StartStreamTranscriptionRequest$SessionId": "<p>A identifier for the transcription session. Use this parameter when you want to retry a session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in the response.</p>",
        "StartStreamTranscriptionResponse$SessionId": "<p>An identifier for a specific transcription session.</p>"
      }
    },
    "Specialty": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$Specialty": "<p>The medical specialty of the clinician or provider.</p>",
        "StartMedicalStreamTranscriptionResponse$Specialty": "<p>The specialty in the medical domain.</p>"
      }
    },
    "Stable": {
      "base": null,
      "refs": {
        "Item$Stable": "<p>If partial result stabilization has been enabled, indicates whether the word or phrase in the item is stable. If <code>Stable</code> is <code>true</code>, the result is stable.</p>"
      }
    },
    "StartMedicalStreamTranscriptionRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartMedicalStreamTranscriptionResponse": {
      "base": null,
      "refs": {
      }
    },
    "StartStreamTranscriptionRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartStreamTranscriptionResponse": {
      "base": null,
      "refs": {
      }
    },
    "String": {
      "base": null,
      "refs": {
        "Alternative$Transcript": "<p>The text that was transcribed from the audio.</p>",
        "BadRequestException$Message": null,
        "ConflictException$Message": null,
        "Entity$Category": "<p>The category of information identified in this entity; for example, PII.</p>",
        "Entity$Type": "<p>The type of PII identified in this entity; for example, name or credit card number.</p>",
        "Entity$Content": "<p>The words in the transcription output that have been identified as a PII entity.</p>",
        "InternalFailureException$Message": null,
        "Item$Content": "<p>The word or punctuation that was recognized in the input audio.</p>",
        "Item$Speaker": "<p>If speaker identification is enabled, shows the speakers identified in the media stream.</p>",
        "LimitExceededException$Message": null,
        "MedicalAlternative$Transcript": "<p>The text that was transcribed from the audio.</p>",
        "MedicalEntity$Category": "<p>The type of personal health information of the medical entity.</p>",
        "MedicalEntity$Content": "<p>The word or words in the transcription output that have been identified as a medical entity.</p>",
        "MedicalItem$Content": "<p>The word or punctuation mark that was recognized in the input audio.</p>",
        "MedicalItem$Speaker": "<p>If speaker identification is enabled, shows the integer values that correspond to the different speakers identified in the stream. For example, if the value of <code>Speaker</code> in the stream is either a <code>0</code> or a <code>1</code>, that indicates that Amazon Transcribe Medical has identified two speakers in the stream. The value of <code>0</code> corresponds to one speaker and the value of <code>1</code> corresponds to the other speaker.</p>",
        "MedicalResult$ResultId": "<p>A unique identifier for the result.</p>",
        "MedicalResult$ChannelId": "<p>When channel identification is enabled, Amazon Transcribe Medical transcribes the speech from each audio channel separately.</p> <p>You can use <code>ChannelId</code> to retrieve the transcription results for a single channel in your audio stream.</p>",
        "Result$ResultId": "<p>A unique identifier for the result. </p>",
        "Result$ChannelId": "<p>When channel identification is enabled, Amazon Transcribe transcribes the speech from each audio channel separately.</p> <p>You can use <code>ChannelId</code> to retrieve the transcription results for a single channel in your audio stream.</p>",
        "ServiceUnavailableException$Message": null
      }
    },
    "Transcript": {
      "base": "<p>The transcription in a <a>TranscriptEvent</a>.</p>",
      "refs": {
        "TranscriptEvent$Transcript": "<p>The transcription of the audio stream. The transcription is composed of all of the items in the results list.</p>"
      }
    },
    "TranscriptEvent": {
      "base": "<p>Represents a set of transcription results from the server to the client. It contains one or more segments of the transcription.</p>",
      "refs": {
        "TranscriptResultStream$TranscriptEvent": "<p>A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream. </p>"
      }
    },
    "TranscriptResultStream": {
      "base": "<p>Represents the transcription result stream from Amazon Transcribe to your application.</p>",
      "refs": {
        "StartStreamTranscriptionResponse$TranscriptResultStream": "<p>Represents the stream of transcription events from Amazon Transcribe to your application.</p>"
      }
    },
    "Type": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$Type": "<p>The type of input audio. Choose <code>DICTATION</code> for a provider dictating patient notes. Choose <code>CONVERSATION</code> for a dialogue between a patient and one or more medical professionanls.</p>",
        "StartMedicalStreamTranscriptionResponse$Type": "<p>The type of audio that was transcribed. </p>"
      }
    },
    "VocabularyFilterMethod": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$VocabularyFilterMethod": "<p>The manner in which you use your vocabulary filter to filter words in your transcript. <code>Remove</code> removes filtered words from your transcription results. <code>Mask</code> masks filtered words with a <code>***</code> in your transcription results. <code>Tag</code> keeps the filtered words in your transcription results and tags them. The tag appears as <code>VocabularyFilterMatch</code> equal to <code>True</code>.</p>",
        "StartStreamTranscriptionResponse$VocabularyFilterMethod": "<p>The vocabulary filtering method used in the media stream.</p>"
      }
    },
    "VocabularyFilterName": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$VocabularyFilterName": "<p>The name of the vocabulary filter you've created that is unique to your account. Provide the name in this field to successfully use it in a stream.</p>",
        "StartStreamTranscriptionResponse$VocabularyFilterName": "<p>The name of the vocabulary filter used in your media stream.</p>"
      }
    },
    "VocabularyName": {
      "base": null,
      "refs": {
        "StartMedicalStreamTranscriptionRequest$VocabularyName": "<p>The name of the medical custom vocabulary to use when processing the real-time stream.</p>",
        "StartMedicalStreamTranscriptionResponse$VocabularyName": "<p>The name of the vocabulary used when processing the stream.</p>",
        "StartStreamTranscriptionRequest$VocabularyName": "<p>The name of the vocabulary to use when processing the transcription job.</p>",
        "StartStreamTranscriptionResponse$VocabularyName": "<p>The name of the vocabulary used when processing the stream.</p>"
      }
    }
  }
}
